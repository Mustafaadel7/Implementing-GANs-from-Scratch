{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1czVdIlqnImH"
      },
      "source": [
        "We're going to create a very basic GAN that is able to generate images of the hand-written digits (0-9) using pytorch framework. If you're not familiar with pytorch, you may find the [PyTorch documentation](https://pytorch.org/docs/stable/index.html) useful.\n",
        "\n",
        "Read my [blog on medium](https://medium.com/@Mustafa77/gans-specialization-part1-8d03c64d42ad) to deeply inderstand how GAN actualy works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU8DDM6l9rZb"
      },
      "source": [
        "# 1. Loading our Toolkit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGhC5aOeJbPq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm # tqdm provides a progress bar for loops and other iterative tasks\n",
        "from torchvision import transforms # For Data Augmentation and Transformation\n",
        "from torchvision.datasets import MNIST # Training dataset\n",
        "from torchvision.utils import make_grid # make_grid is a utility function to visualize a batch of images at once.\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt  # Data Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mvjjan17qHjq"
      },
      "source": [
        "# 2. Loading our Dataset (MNIST Dataset).\n",
        "For the sake of simplicity, the training images that We'll be using is from [MNIST Dataset](http://yann.lecun.com/exdb/mnist/). It contains 60,000 images of handwritten digits, from 0 to 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaZ1dd-8HJqe",
        "outputId": "bb1252ff-4f0c-44a6-c99f-ff3b8c23f35d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 498kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.50MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.42MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ---------> Load MNIST dataset as tensors\n",
        "dataloader = DataLoader( MNIST('.', download= True, transform=transforms.ToTensor()), batch_size= 128, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1A1M6kpnfxw"
      },
      "source": [
        "# 3. Building The Generator.\n",
        "We'll start by creating the generator's NN, coposed of 4 blocks, each block should include a [linear transformation](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) to map to another shape, a [batch normalization](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html) for stabilizing and accelerating the training process, and finally a non-linear activation function ( We use [ReLU here](https://pytorch.org/docs/master/generated/torch.nn.ReLU.html)) so the output can be transformed in complex ways. You will learn more about activations and batch normalization later in part2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvO7h0LYnEJZ"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=10, im_dim=784, hidden_dim=128):\n",
        "        super(Generator, self).__init__() # To make sure that the child class behaviour is just like the parent class\n",
        "        self.gen = nn.Sequential(\n",
        "            self.generator_block(z_dim, hidden_dim),\n",
        "            self.generator_block(hidden_dim, hidden_dim * 2),\n",
        "            self.generator_block(hidden_dim * 2, hidden_dim * 4),\n",
        "            self.generator_block(hidden_dim * 4, hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, im_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def generator_block(self, input_dim, output_dim):\n",
        "      return nn.Sequential(\n",
        "        nn.Linear(input_dim, output_dim),\n",
        "        nn.BatchNorm1d(output_dim),\n",
        "        nn.ReLU(inplace=True))\n",
        "\n",
        "    def forward(self, noise):\n",
        "        return self.gen(noise)\n",
        "\n",
        "        '''\n",
        "        In OOP, the `forward` method plays a significant role, particularly in the context of classes that represent models e.g., build a NN.\n",
        "        Here are the key points regarding its importance:\n",
        "        1. Encapsulation of Functionality 2. Interface for Model Execution 3. Abstraction 4. Modularity\n",
        "        5. Ease of Testing and Debugging 6. Support for Inheritance and Polymorphism 7.Alignment with Frameworks\n",
        "'''\n",
        "\n",
        "    def get_gen(self):\n",
        "        return self.gen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9fScH98nkYH"
      },
      "source": [
        "# 4. Building The Discriminator.\n",
        "The second component that you need to construct is the discriminator.\n",
        "We use leakyReLU to prevent the \"dying ReLU\" problem, which refers to the phenomenon where the parameters stop changing due to consistently negative values passed to a ReLU, which result in a zero gradient\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aA4AxGnmpuPq"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, im_dim=784, hidden_dim=128):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            self.discriminator_block(im_dim, hidden_dim * 4),\n",
        "            self.discriminator_block(hidden_dim * 4, hidden_dim * 2),\n",
        "            self.discriminator_block(hidden_dim * 2, hidden_dim),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "            ## nn.Sigmoid()\n",
        "        )\n",
        "    def discriminator_block(self, input_dim, output_dim):\n",
        "      return nn.Sequential(\n",
        "         nn.Linear(input_dim, output_dim),\n",
        "         nn.LeakyReLU(0.2, inplace=True))\n",
        "\n",
        "    def forward(self, image):\n",
        "        return self.disc(image)\n",
        "\n",
        "    def get_disc(self):\n",
        "        # Returns the sequential model\n",
        "        return self.disc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FLX69EaqRjn"
      },
      "source": [
        "# 5. Random Noise Vector.\n",
        "The noise vector has the important role of insuring that the generated images don't all look the same.\n",
        "<br> We'll generate it randomly by sampling random numbers from the normal distribution.\n",
        "<br> Since multiple images will be processed per pass, we'll generate all the noise vectors at once.\n",
        "\n",
        "Note that whenever you create a new tensor using torch.ones, torch.zeros, or torch.randn, you either need to create it on the target device, e.g. `torch.ones(3, 3, device=device)`, or move it onto the target device using `torch.ones(3, 3).to(device)`. You do not need to do this if you're creating a tensor by manipulating another tensor or by using a variation that defaults the device to the input, such as `torch.ones_like`. In general, use `torch.ones_like` and `torch.zeros_like` instead of `torch.ones` or `torch.zeros` where possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8COwJ9PkqUyd"
      },
      "outputs": [],
      "source": [
        "def get_noise(n_samples, z_dim, device='cpu'):\n",
        "    return torch.randn(n_samples,z_dim, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-GLzjUJGX6r"
      },
      "source": [
        "# 6. Intialize the generator and discriminator and their Optimizers.\n",
        "Now, we can initialize our generator and discriminator optimizers. Note that each optimizer only takes the parameters of one particular model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDFRZ8tg_Y57"
      },
      "outputs": [],
      "source": [
        "z_dim = 64\n",
        "\n",
        "gen = Generator(z_dim)\n",
        "gen_opt = torch.optim.Adam(gen.parameters(), lr= 0.0001)\n",
        "disc = Discriminator()\n",
        "disc_opt = torch.optim.Adam(disc.parameters(), lr= 0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iCTg3w4_Zw6"
      },
      "source": [
        "# 7. Create Loss Functions.\n",
        "We are in need of creating functions to calculate the discriminator's loss and the generator's loss. This is how the discriminator and generator will know how they are doing and improve themselves. Since the generator is needed when calculating the discriminator's loss, you will need to call .detach() on the generator result to ensure that only the discriminator is updated!\n",
        "\n",
        "Note, We've efined a loss function (`criterion`) to encourage to use `torch.ones_like` and `torch.zeros_like` instead of `torch.ones` or `torch.zeros`. If you use `torch.ones` or `torch.zeros`, you'll need to pass `device=device` to them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZunMB7qILkI"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYzBtiYyz8IJ"
      },
      "outputs": [],
      "source": [
        "def get_disc_loss(gen, disc, criterion, real, num_images, z_dim= 64):\n",
        "    fake_noise = get_noise(num_images, z_dim)\n",
        "    fake = gen(fake_noise)\n",
        "    disc_fake_pred = disc(fake.detach())\n",
        "\n",
        "    disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
        "    disc_real_pred = disc(real)\n",
        "    disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
        "\n",
        "    return (disc_fake_loss + disc_real_loss) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV_8i6y30nTE"
      },
      "outputs": [],
      "source": [
        "def get_gen_loss(gen, disc, criterion, num_images, z_dim= 64):\n",
        "    fake_noise = get_noise(num_images, z_dim)\n",
        "    fake = gen(fake_noise)\n",
        "    disc_fake_pred = disc(fake)\n",
        "    return criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhylBRPgNBIk"
      },
      "source": [
        "# 8. Visualize a Grid of Images.\n",
        "We'll create a visualizer function (show_tensor_images) to visualize a grid of images to help investigate the generated images and keep track the generator progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QmcUsMOM6lf"
      },
      "outputs": [],
      "source": [
        "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
        "    '''\n",
        "    Function for visualizing images in a uniform grid : Given a tensor of images, number of images, and size per image.\n",
        "    Parameters:\n",
        "              image_tensor: This is the input tensor containing the image data.\n",
        "              num_images: The total number of images to display in the grid.\n",
        "              size: The dimensions of each image (default is `(1, 28, 28)`),\n",
        "              indicating that images are grayscale with height and width of 28 pixels.\n",
        "    Functionality:\n",
        "                  - It 1st detaches the tensor from the computation graph,\n",
        "                  and reshapes it to separate individual images using view(-1, *size),\n",
        "                  where -1 allows for automatic dimension calculation based on the number of images.\n",
        "                  - It then creates a grid layout of images using `make_grid`,\n",
        "                  which arranges the specified number of images 'num_images' into a uniform grid with 5 images per row.\n",
        "                  - Finally, the generated grid is displayed using `plt.imshow`,\n",
        "                  adjusting its dimensions with `permute` to ensure the color channels are in the right order,\n",
        "                  and `squeeze` to remove any singleton dimensions.\n",
        "\n",
        "    '''\n",
        "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vua5_hRMRb60"
      },
      "source": [
        "# 9. Training (put everything together)\n",
        "\n",
        "For each epoch, we'll process the entire dataset in batches. For every batch, we'll need to update the discriminator and generator weights. Note that you may see a loss to be greater than 1, this is okay since binary cross entropy loss can be any positive number for a sufficiently confident wrong guess.\n",
        "\n",
        "It’s also often the case that the discriminator will outperform the generator, especially at the start, because its job is easier. It's important that neither one gets too good (near-perfect accuracy), which would cause the entire model to stop learning. Balancing the 2 models is actually remarkably hard to do in a standard GAN.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWbRAJqvCNvc"
      },
      "outputs": [],
      "source": [
        "n_epochs = 200\n",
        "display_step = 500\n",
        "batch_size = 128\n",
        "cur_step = 0\n",
        "mean_generator_loss = 0\n",
        "mean_discriminator_loss = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXptQZcwrBrq"
      },
      "outputs": [],
      "source": [
        "for epoch in range(n_epochs):\n",
        "    for real, _ in tqdm(dataloader):\n",
        "        cur_batch_size = len(real)\n",
        "        real = real.view(cur_batch_size, -1)\n",
        "        disc_opt.zero_grad()\n",
        "        gen_opt.zero_grad()\n",
        "        disc_loss= get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim)\n",
        "        disc_loss.backward(retain_graph=True)\n",
        "        disc_opt.step()\n",
        "        gen_loss = get_gen_loss(gen, disc, criterion, cur_batch_size, z_dim)\n",
        "        gen_loss.backward()\n",
        "        gen_opt.step()\n",
        "        mean_discriminator_loss += disc_loss.item() / display_step\n",
        "        mean_generator_loss += gen_loss.item() / display_step\n",
        "        if cur_step % display_step == 0 and cur_step > 0:\n",
        "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
        "            fake_noise = get_noise(cur_batch_size, z_dim)\n",
        "            fake = gen(fake_noise)\n",
        "            show_tensor_images(fake)\n",
        "            show_tensor_images(real)\n",
        "            mean_generator_loss = 0\n",
        "            mean_discriminator_loss = 0\n",
        "        cur_step += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJsk2So5Va7J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "coursera": {
      "schema_names": [
        "GANSC1-1A"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}